# HireWire Scripts

Scripts organisÃ©s par catÃ©gorie pour une meilleure maintenabilitÃ©.

## ğŸš€ Utilisation rapide

```bash
# Script principal - point d'entrÃ©e unique
./scripts/main.sh help

# Exemples d'utilisation
./scripts/main.sh data-entry manage     # Interface de saisie de donnÃ©es
./scripts/main.sh etl run              # Pipeline ETL complet
./scripts/main.sh setup init           # Initialiser DuckDB
./scripts/main.sh testing test         # Tester la configuration
```

## ğŸ“ Structure des dossiers

```
scripts/
â”œâ”€â”€ main.sh                 # Point d'entrÃ©e principal
â”œâ”€â”€ data_entry/             # Scripts de saisie de donnÃ©es
â”‚   â”œâ”€â”€ manage_data.sh      # Interface interactive
â”‚   â”œâ”€â”€ list_data.sh        # Lister les donnÃ©es
â”‚   â”œâ”€â”€ add_company.sh      # Ajouter une entreprise
â”‚   â”œâ”€â”€ add_job_position.sh # Ajouter un poste
â”‚   â”œâ”€â”€ add_process.sh      # Ajouter un processus d'entretien
â”‚   â”œâ”€â”€ add_interview.sh    # Ajouter un entretien
â”‚   â””â”€â”€ add_outcome.sh      # Ajouter un rÃ©sultat
â”œâ”€â”€ etl/                    # Pipeline DBT
â”‚   â””â”€â”€ etl_runner.sh       # Pipeline DBT complet
â”œâ”€â”€ setup/                  # Scripts d'initialisation
â”‚   â””â”€â”€ init_duckdb.sh      # Initialiser DuckDB
â””â”€â”€ testing/                # Scripts de test
    â””â”€â”€ test_setup.sh       # Tester la configuration
```

## ğŸ“Š Data Entry

Scripts pour ajouter des donnÃ©es dans PostgreSQL :

```bash
# Interface complÃ¨te de gestion
./scripts/main.sh data-entry manage

# Scripts individuels
./scripts/main.sh data-entry add-company
./scripts/main.sh data-entry add-job
./scripts/main.sh data-entry list
```

## ğŸ”„ DBT Pipeline (3 couches)

Pipeline DBT pure en 3 couches :

```bash
# Pipeline complet : PostgreSQL â†’ Staging â†’ Intermediate â†’ Marts
./scripts/main.sh etl run

# Par Ã©tapes si besoin
docker-compose exec dbt sh -c "cd /usr/app && dbt run --select staging"
docker-compose exec dbt sh -c "cd /usr/app && dbt run --select intermediate"
docker-compose exec dbt sh -c "cd /usr/app && dbt run --select marts"
```

Le pipeline suit ce flow :
1. **PostgreSQL** : DonnÃ©es brutes transactionnelles
2. **Staging** : Copie des donnÃ©es vers DuckDB (6 tables)
3. **Intermediate** : Nettoyage et enrichissement (5 tables)
4. **Marts** : Tables "Gold" pour Metabase (8 tables)
5. **Metabase** : Visualisation des tables marts

## âš™ï¸ Setup & Testing

```bash
# Initialiser DuckDB
./scripts/main.sh setup init

# Tester la configuration
./scripts/main.sh testing test
```

## ğŸ”§ DÃ©veloppement

### Ajouter un nouveau script

1. Placer le script dans le bon dossier (`data_entry/`, `etl/`, `setup/`, `testing/`)
2. Le rendre exÃ©cutable : `chmod +x scripts/category/script.sh`
3. Ajouter l'alias dans `main.sh` si nÃ©cessaire

### Conventions

- **Scripts bash** : Extension `.sh`, shebang `#!/bin/bash`, `set -e` pour arrÃªt sur erreur
- **Scripts Python** : Extension `.py`, shebang `#!/usr/bin/env python3`
- **Nommage** : snake_case, descriptif de l'action
- **Documentation** : Commentaires au dÃ©but du fichier

## ğŸ“ˆ Flux de donnÃ©es

```mermaid
graph LR
    A[Data Entry<br/>Scripts] --> B[PostgreSQL<br/>Raw Data]
    B --> C[ETL Script<br/>Python]
    C --> D[DuckDB<br/>Star Schema]
    D --> E[DBT Models<br/>Analytics]
    E --> F[Metabase<br/>Dashboards]
```

## ğŸ³ IntÃ©gration Docker

Les scripts utilisent les containers Docker :
- `postgres` : Base de donnÃ©es transactionnelle
- `duckdb_init` : Base de donnÃ©es analytique
- `dbt` : Transformations de donnÃ©es
- `metabase` : Visualisation

Volumes partagÃ©s :
- `scripts/` â†’ `/scripts` (dans duckdb_init)
- `dbt_project/` â†’ `/usr/app` (dans dbt)